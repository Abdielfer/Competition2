{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math, decimal\n",
    "from math import exp\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "seedRF = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", index_col = None)\n",
    "y = train[['LABELS']]\n",
    "x = train.drop('LABELS', axis=1)\n",
    "xMean = x.mean()\n",
    "test_nolabels = pd.read_csv(\"test_nolabels.csv\", index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting trainig/Validation\n",
    "x_train, x_validation, y_train, y_validation = train_test_split( x,y, test_size=0.2)\n",
    "\n",
    "## Replacing possible missing values\n",
    "x_train = x_train.fillna(xMean)\n",
    "x_validation = x_validation.fillna(xMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data shape exploration\n",
    "print(\"\",np.shape(x_train),\"  :\",np.shape(x_validation) )\n",
    "print(\"Label balance on Training set: \", \"\\n\", y_train['LABELS'].value_counts())\n",
    "print(\"Label balance on Validation set: \", \"\\n\", y_validation['LABELS'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To adapt the prediction to Kaggel format of submission \n",
    "def formating_prediction(predictions): \n",
    "        '''\n",
    "        return de predicted classes from the hypotesis function result (sigmoid(W,X))\n",
    "        @hypotesis : matrix of probablilities \n",
    "        '''\n",
    "        y_hat = pd.DataFrame({'S.No' : [],'LABELS' : []}, dtype=np.int8) \n",
    "        for i in range(len(predictions)):\n",
    "            y_hat.loc[i] = [i,predictions[i]]\n",
    "       \n",
    "        return pd.DataFrame(data = y_hat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction based on domain knowledge (In progress)\n",
    "ndvi_list = {'NDVI_jan','NDVI_feb','NDVI_mar','NDVI_apr','NDVI_may','NDVI_jun','NDVI_jul','NDVI_aug','NDVI_sep','NDVI_oct','NDVI_nov','NDVI_dec'}\n",
    "## Extrae los NDVI y escatter contra las labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some helpers function\n",
    "def predictOnSet(modelFilename, x_test):\n",
    "        # # load the model from disk to predict new dataSet\n",
    "    loaded_model = pickle.load(open(modelFilename, 'rb'))\n",
    "    prediction = rf_classifier.predict(x_test)\n",
    "    return prediction\n",
    "\n",
    "def savingModels(classifier, modelFileName):\n",
    "    '''\n",
    "    NOTE: Do not forget the extention = *.pkl\n",
    "    Save as : 'modelFileName.pkl'\n",
    "    '''\n",
    "    return joblib.dump(classifier, modelFileName)\n",
    "   \n",
    "def savePrediction(prediction, filename):\n",
    "    '''\n",
    "    Save predictions\n",
    "    @argument: filename: Remenber EXTENTION 'filename.csv'\n",
    "    '''\n",
    "    prediction = prediction.astype('int32') #exsure prediction as integer\n",
    "    predictions_DF = formating_prediction(prediction)\n",
    "    return predictions_DF.to_csv(filename, index = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modle evaluation\n",
    "def lrMetricRocAuc(y_probability, validation_y):\n",
    "    '''\n",
    "    @argument: y_probability : the probability to be goal=1 from the LR model.\n",
    "    @argument: validation_y: True labels.\n",
    "    Return: proportion of \"false_positive\" and \"true_positive\". The result of AUC metric \"roc_auc_lr\".\n",
    "    '''\n",
    "    false_positive, true_positive, _ = roc_curve(validation_y, y_probability) \n",
    "    roc_auc_lr = auc(false_positive, true_positive)\n",
    "    return false_positive, true_positive, roc_auc_lr\n",
    "\n",
    "## Show some evaluation criteria on the clasifier\n",
    "def evaluate_model(x_train, y_train, x_test, y_test, classifier):\n",
    "    features = x_train.columns\n",
    "    train_Prediction = classifier.predict(x_train)\n",
    "    train_PredictedProb = classifier.predict_proba(x_train)[:, 1]\n",
    "    ### Inclure ROC curve #####\n",
    "    test_Prediction = classifier.predict(x_test)\n",
    "    test_PredictedProb = classifier.predict_proba(x_test)[:, 1]\n",
    "    ### Inclure ROC curve #####\n",
    "    fi_model = pd.DataFrame({'feature': features,\n",
    "                   'importance': classifier.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)     \n",
    "    print(Counter(probs))\n",
    "    print(Counter(predictions))\n",
    "    return fi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBOOST\n",
    "def xgboost(X_train, y_train, X_test):    \n",
    "    # fit model no training data\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy xgboost: %.2f%%\" % (accuracy * 100.0))\n",
    "    predictionsDF = formating_prediction(predictions)\n",
    "    return model, accuracy, predictionsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest \n",
    "def randomForest(x_train, y_train, x_validation, y_validation, estimators):\n",
    "    '''\n",
    "    Performe random forest, in the simples way, from Skl library\n",
    "    @estimators: NUmber of estimators\n",
    "    return: model \"classifier_LR\" and a prediction over a x_validation\n",
    "    '''\n",
    "    y_train = np.array(y_train)\n",
    "    y_train =  y_train.ravel()#np.reshape(y_train,(-1,1))\n",
    "    rf_classifier = RandomForestClassifier(n_estimators = estimators, criterion = 'entropy', random_state = 42)\n",
    "    rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "    # Predicting on the validation set\n",
    "    prediction = rf_classifier.predict(x_validation)\n",
    "    accuracy = accuracy_score(y_validation, prediction)\n",
    "    prediction = prediction.astype('int32')\n",
    "    savingModels(rf_classifier, \"rf_simple.pkl\")\n",
    "    ### Comment/Uncomment next line to save prediction on ValidationSet as *.csv\n",
    "    # savePrediction(prediction, \"rf_validatoinPredicted.csv\")\n",
    "    predictions_DF = formating_prediction(prediction)\n",
    "    return rf_classifier, accuracy, predictions_DF \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Ramdomized RF  ####\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(100, 200).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state = seedRF)\n",
    "\n",
    "# Create the random search model\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'roc_auc', cv = 3, \n",
    "                        n_iter = 10, verbose = 1, random_state=seedRF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random searsh  \n",
    "y_train = np.array(y_train).ravel()\n",
    "rs.fit(x_train, y_train)\n",
    "print(rs.best_params_, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Working with best estimator from RandomizedSearch \n",
    "best_model = rs.best_estimator_\n",
    "savingModels(best_model, \"rf_RandomSearch.pkl\")\n",
    "\n",
    "test_nolabels_prediction = predictOnSet(best_model, test_nolabels)\n",
    "savePrediction(test_nolabels_prediction, 'first_rfSearch_noLabelPrediction.csv')\n",
    "\n",
    "fi_model = evaluate_Rf(x_train, y_train, x_validation, y_validation, test_nolabels_prediction)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "for ind_tree in best_model.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}', '\\n')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and format prediction\n",
    "rf_classifier, accuracy, predictions_DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and sve predisction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eedf6d570df146484a47fd0eae676e78ed396670004acbd373a3bc98c7d3284"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ift6758-conda-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
