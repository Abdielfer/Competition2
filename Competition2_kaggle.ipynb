{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math, decimal\n",
    "from math import exp\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV,GridSearchCV \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_curve, auc, roc_auc_score\n",
    "from sklearn.calibration import calibration_curve, CalibrationDisplay\n",
    "from xgboost import XGBClassifier,XGBRFClassifier\n",
    "from collections import Counter\n",
    "seedRF = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", index_col = None)\n",
    "y = train[['LABELS']]\n",
    "x = train.drop('LABELS', axis=1)\n",
    "xMean = x.mean()\n",
    "x = x.fillna(xMean)\n",
    "test_nolabels = pd.read_csv(\"test_nolabels.csv\", index_col = None)\n",
    "test_nolabels = test_nolabels.fillna(xMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting trainig/Validation\n",
    "x_train, x_validation, y_train, y_validation = train_test_split( x,y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data shape exploration\n",
    "print(\"\",np.shape(x_train),\"  :\",np.shape(x_validation) )\n",
    "print(\"Label balance on Training set: \", \"\\n\", y_train['LABELS'].value_counts())\n",
    "print(\"Label balance on Validation set: \", \"\\n\", y_validation['LABELS'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction based on domain knowledge (In progress)\n",
    "ndvi_list = {'NDVI_jan','NDVI_feb','NDVI_mar','NDVI_apr','NDVI_may','NDVI_jun','NDVI_jul','NDVI_aug','NDVI_sep','NDVI_oct','NDVI_nov','NDVI_dec'}\n",
    "## Extrae los NDVI y escatter contra las labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some helpers function\n",
    "# To adapt the prediction to Kaggel format of submission \n",
    "def formating_prediction(predictions): \n",
    "        '''\n",
    "        return de predicted classes from the hypotesis function result (sigmoid(W,X))\n",
    "        @hypotesis : matrix of probablilities \n",
    "        '''\n",
    "        y_hat = pd.DataFrame({'S.No' : [],'LABELS' : []}, dtype=np.int8) \n",
    "        for i in range(len(predictions)):\n",
    "            y_hat.loc[i] = [i,predictions[i]]\n",
    "        return pd.DataFrame(data = y_hat) \n",
    "\n",
    "def predictOnSet(model, x_test):\n",
    "    prediction = model.predict(x_test)\n",
    "    return prediction\n",
    "\n",
    "def savingModels(classifier, modelFileName):\n",
    "    '''\n",
    "    NOTE: Do not forget the extention = *.pkl\n",
    "    Save as : 'modelFileName.pkl'\n",
    "    '''\n",
    "    joblib.dump(classifier, modelFileName)\n",
    "\n",
    "\n",
    "def importModel(modefname):\n",
    "    model = joblib.load(modefname)\n",
    "    return model\n",
    "\n",
    "def savePrediction(prediction, filename):\n",
    "    '''\n",
    "    Save predictions\n",
    "    @argument: filename: Remenber EXTENTION 'filename.csv'\n",
    "    '''\n",
    "    prediction = prediction.astype('int32') #exsure prediction as integer\n",
    "    predictions_DF = formating_prediction(prediction)\n",
    "    return predictions_DF.to_csv(filename, index = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modle evaluation\n",
    "def metric_RocAuc(y_probability, y_validation, estimator_name):\n",
    "    '''\n",
    "    Calculate and plt ROC metric\n",
    "    @argument: y_probability : the probability class=1.\n",
    "    @argument: y_validation: True labels.\n",
    "    fpr, tpr = false_positive, true_positive.\n",
    "    Return: \"false_positive\" and \"true_positive\", ROC_auc metric.\n",
    "    '''\n",
    "    fpr, tpr, _ = roc_curve(y_validation, y_probability) \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig, axes = plt.subplots(constrained_layout=True,figsize=(5,3), dpi=150)\n",
    "    fig.suptitle(estimator_name)\n",
    "    axes.plot([0, 1], [0, 1], color= 'k',linestyle=\"--\") # perfect fit \n",
    "    display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                       estimator_name=estimator_name)\n",
    "    display.plot(ax=axes)\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "## Show some evaluation criteria on the clasifier\n",
    "def evaluate_model(x_train, y_train, x_validation, y_validation, classifier):\n",
    "    features = x_train.columns\n",
    "    validation_Prediction = classifier.predict(x_validation)\n",
    "    validation_PredictedProb = classifier.predict_proba(x_validation)[:, 1]\n",
    "    ### ROC metric and curve #####\n",
    "    clasifierName = type(classifier).__name__\n",
    "    metric_RocAuc(validation_PredictedProb, y_validation,clasifierName)\n",
    "    fi_model = pd.DataFrame({'feature': features,\n",
    "                   'importance': classifier.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)\n",
    "    clasifierNameExtended = clasifierName + \"_info_fi\"     \n",
    "    fi_model.to_csv(clasifierNameExtended, index = None)\n",
    "    return fi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBOOST\n",
    "def xgboost(x_train, y_train, x_validation, y_validation):    \n",
    "    # fit model no training data\n",
    "    model = XGBClassifier(use_label_encoder=False)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_validation)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_validation, predictions)\n",
    "    print(\"Accuracy xgboost: %.2f%%\" % (accuracy * 100.0))\n",
    "    predictionsDF = formating_prediction(predictions)\n",
    "    return model, accuracy, predictionsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest \n",
    "def randomForest(x_train, y_train, x_validation, y_validation, estimators):\n",
    "    '''\n",
    "    Performe random forest, in the simples way, from Skl library\n",
    "    @estimators: NUmber of estimators\n",
    "    return: model \"classifier_LR\" and a prediction over a x_validation\n",
    "    '''\n",
    "    y_train = np.array(y_train)\n",
    "    y_train =  y_train.ravel()#np.reshape(y_train,(-1,1))\n",
    "    rf_classifier = RandomForestClassifier(n_estimators = estimators, criterion = 'entropy', random_state = 42)\n",
    "    rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "    # Predicting on the validation set\n",
    "    prediction = rf_classifier.predict(x_validation)\n",
    "    accuracy = accuracy_score(y_validation, prediction)\n",
    "    prediction = prediction.astype('int32')\n",
    "    savingModels(rf_classifier, \"rf_simple.pkl\")\n",
    "    ### Comment/Uncomment next line to save prediction on ValidationSet as *.csv\n",
    "    # savePrediction(prediction, \"rf_validatoinPredicted.csv\")\n",
    "    predictions_DF = formating_prediction(prediction)\n",
    "    return rf_classifier, accuracy, predictions_DF \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Ramdomized RF  ####\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(10, 200,20).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state = seedRF)\n",
    "\n",
    "# Create the random search model\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'roc_auc', cv = 3, \n",
    "                        n_iter = 10, verbose = 1, random_state=seedRF)\n",
    "\n",
    "\n",
    "# Random searsh  \n",
    "y_train = np.array(y_train).ravel()\n",
    "rs.fit(x_train, y_train)\n",
    "print(rs.best_params_, \"\\n\")\n",
    "\n",
    "### Working with best estimator from RandomizedSearch \n",
    "best_model = rs.best_estimator_\n",
    "savingModels(best_model, \"rf_RandomSearch.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Working with best estimator from RandomizedSearch \n",
    "best_model = rs.best_estimator_\n",
    "savingModels(best_model, \"rf_RandomSearch.pkl\")\n",
    "\n",
    "test_nolabels_prediction = predictOnSet(best_model, test_nolabels)\n",
    "savePrediction(test_nolabels_prediction, 'first_rfSearch_noLabelPrediction.csv')\n",
    "\n",
    "fi_model = evaluate_model(x_train, y_train, x_validation, y_validation, test_nolabels_prediction)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "for ind_tree in best_model.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}', '\\n')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recording = dict()\n",
    "# classifier = joblib.load(\"rf_RandomSearch.pkl\")\n",
    "for i in range(5): \n",
    "    x_train, x_validation, y_train, y_validation = train_test_split(x,y, test_size=0.2)\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_validation)\n",
    "    accuracy = accuracy_score(y_validation, y_pred)\n",
    "    recording[str(i)] = accuracy\n",
    "    print(str(i) + \"_Accuracy: %.2f%%\" % (accuracy))\n",
    "    evaluate_model(x_train, y_train, x_validation, y_validation, classifier)\n",
    "    modelFileName = str(i)+\"recurentRandomSplitRF.pkl\"\n",
    "    joblib.dump(classifier, modelFileName)\n",
    "    test_nolabels_prediction = predictOnSet(classifier, test_nolabels)\n",
    "    predictionFilename = str(i)+\"predictionFilename.csv\"\n",
    "    savePrediction(test_nolabels_prediction, predictionFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = importModel('rf_RandomSearch.pkl')\n",
    "y_pred = rf_model.predict(x_validation)\n",
    "accuracy = accuracy_score(y_validation, y_pred)\n",
    "print(\"Accuracy xgboost: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultXGB_CV = []\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric= 'logloss')\n",
    "for i in range(20):\n",
    "    x_train, x_validation, y_train, y_validation = train_test_split( x,y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBRFClassifier(use_label_encoder=False,subsample=0.9, colsample_bynode=0.2)\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(50, 400, 4).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3,20,4).astype(int)),\n",
    "    'max_features': [None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "# Create the random search model\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'roc_auc', cv = 3, \n",
    "                        n_iter = 4, verbose = 1, random_state=seedRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = rs.best_estimator_\n",
    "y_pred = best_model.predict(x_validation)\n",
    "accuracy = accuracy_score(y_validation, y_pred)\n",
    "print(\"Accuracy xgboost: %.2f%%\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- S.No\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Unnamed: 0\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# best_model = rs.best_estimator_\n",
    "savingModels(classifier, \"RF_multipleRandomSplit.pkl\")\n",
    "\n",
    "test_nolabels_prediction = predictOnSet(classifier, test_nolabels)\n",
    "savePrediction(test_nolabels_prediction, 'RF_multipleRandomSplit.csv')\n",
    "\n",
    "# fi_model = evaluate_model(x_train, y_train, x_validation, y_validation, classifier)\n",
    "# testNoLabelFIrst = pd.read_csv(\"first_rfSearch_noLabelPrediction.csv\", index_col = None)\n",
    "# accuracy = accuracy_score(testNoLabelFIrst[['LABELS']], test_nolabels_prediction[['LABELS']])\n",
    "# print(\"Accuracy xgboost: %.2f%%\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy xgboost: 0.79%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_validation)\n",
    "accuracy = accuracy_score(y_validation, y_pred)\n",
    "y = \"Accuracy xgboost: %.2f%%\" % (accuracy)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i =0\n",
    "clasifierName = \"xgboost_singleTest_\" + str(0) + \"_.pkl\"\n",
    "print(clasifierName)\n",
    "savingModels(model, clasifierName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(x_train, y_train, x_validation, y_validation, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nolabels_prediction = model.predict(test_nolabels)\n",
    "\n",
    "print(test_nolabels_prediction)\n",
    "test_nolabels_prediction= formating_prediction(test_nolabels_prediction)\n",
    "# test_nolabels_prediction.to_csv(\"testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNoLabelFIrst = pd.read_csv(\"first_rfSearch_noLabelPrediction.csv\", index_col = None)\n",
    "accuracy = accuracy_score(testNoLabelFIrst[['LABELS']], test_nolabels_prediction[['LABELS']])\n",
    "print(\"Accuracy xgboost: %.2f%%\" % (accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eedf6d570df146484a47fd0eae676e78ed396670004acbd373a3bc98c7d3284"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
