{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", index_col = None)\n",
    "y = train[['LABELS']]\n",
    "x = train.drop('LABELS', axis=1)\n",
    "xMean = x.mean()\n",
    "x = x.fillna(xMean)\n",
    "test_nolabels = pd.read_csv(\"test_nolabels.csv\", index_col = None)\n",
    "test_nolabels = test_nolabels.fillna(xMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_list = {'NDVI_jan','NDVI_feb','NDVI_mar','NDVI_apr','NDVI_may','NDVI_jun','NDVI_jul','NDVI_aug','NDVI_sep','NDVI_oct','NDVI_nov','NDVI_dec'}\n",
    "ndviDF = x[ndvi_list]\n",
    "# ndviDF['LABELS'] = y['LABELS']\n",
    "print(ndviDF.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "toposElevation = {\"topo_elevation_jan\",'topo_elevation_feb','topo_elevation_mar','topo_elevation_apr','topo_elevation_may','topo_elevation_jun','topo_elevation_jul','topo_elevation_aug','topo_elevation_sep','topo_elevation_oct','topo_elevation_nov','topo_elevation_dec'}\n",
    "topoSlope = {'topo_slope_jan','topo_slope_feb','topo_slope_mar','topo_slope_apr','topo_slope_may','topo_slope_aug','topo_slope_jun','topo_slope_jul','topo_slope_sep','topo_slope_oct','topo_slope_nov','topo_slope_dec'}\n",
    "topoElevationDF = x[toposElevation]\n",
    "topoElevationMean = topoElevationDF.mean(axis=1)\n",
    "x = x.drop(toposElevation,axis=1)\n",
    "x['topoElevationMean'] = topoElevationMean\n",
    "topoSlopeDF = x[topoSlope]\n",
    "topoSlopeMean = topoSlopeDF.mean(axis=1)\n",
    "x = x.drop(topoSlope, axis=1)\n",
    "x['topoSlope'] = topoSlopeMean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing No_label datase:\n",
    "test_nolabels = test_nolabels.fillna(xMean)\n",
    "test_nolabels = test_nolabels.drop(toposElevation, axis=1)\n",
    "test_nolabels = test_nolabels.drop(topoSlope, axis=1)\n",
    "test_nolabels['topoElevationMean'] = topoElevationMean\n",
    "test_nolabels['topoSlope'] = topoSlopeMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> /n <class 'numpy.ndarray'> /n <class 'pandas.core.frame.DataFrame'> /n <class 'numpy.ndarray'> /n\n"
     ]
    }
   ],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split( x,y, test_size=0.2)\n",
    "y_train = (np.array(y_train).astype('int')).ravel()\n",
    "y_validation = (np.array(y_validation).astype('int')).ravel()\n",
    "\n",
    "print(type(x_train),\"/n\", type(y_train),\"/n\", type(x_validation),\"/n\", type(y_validation),\"/n\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some helpers function\n",
    "# To adapt the prediction to Kaggel format of submission \n",
    "def formating_prediction(predictions): \n",
    "        '''\n",
    "        return de predicted classes from the hypotesis function result (sigmoid(W,X))\n",
    "        @hypotesis : matrix of probablilities \n",
    "        '''\n",
    "        y_hat = pd.DataFrame({'S.No' : [],'LABELS' : []}, dtype=np.int8) \n",
    "        for i in range(len(predictions)):\n",
    "            y_hat.loc[i] = [i,predictions[i]]\n",
    "        return pd.DataFrame(data = y_hat) \n",
    "\n",
    "def predictOnSet(model, x_test):\n",
    "    prediction = model.predict(x_test)\n",
    "    return prediction\n",
    "\n",
    "def savingModels(classifier, modelFileName):\n",
    "    '''\n",
    "    NOTE: Do not forget the extention = *.pkl\n",
    "    Save as : 'modelFileName.pkl'\n",
    "    '''\n",
    "    joblib.dump(classifier, modelFileName)\n",
    "\n",
    "\n",
    "def importModel(modefname):\n",
    "    model = joblib.load(modefname)\n",
    "    return model\n",
    "\n",
    "def savePrediction(prediction, filename):\n",
    "    '''\n",
    "    Save predictions\n",
    "    @argument: filename: Remenber EXTENTION 'filename.csv'\n",
    "    '''\n",
    "    prediction = prediction.astype('int32') #exsure prediction as integer\n",
    "    predictions_DF = formating_prediction(prediction)\n",
    "    return predictions_DF.to_csv(filename, index = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modle evaluation\n",
    "def metric_RocAuc(y_probability, y_validation, estimator_name):\n",
    "    '''\n",
    "    Calculate and plt ROC metric\n",
    "    @argument: y_probability : the probability class=1.\n",
    "    @argument: y_validation: True labels.\n",
    "    fpr, tpr = false_positive, true_positive.\n",
    "    Return: \"false_positive\" and \"true_positive\", ROC_auc metric.\n",
    "    '''\n",
    "    fpr, tpr, _ = roc_curve(y_validation, y_probability) \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig, axes = plt.subplots(constrained_layout=True,figsize=(5,3), dpi=150)\n",
    "    fig.suptitle(estimator_name)\n",
    "    axes.plot([0, 1], [0, 1], color= 'k',linestyle=\"--\") # perfect fit \n",
    "    display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                       estimator_name=estimator_name)\n",
    "    display.plot(ax=axes)\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "## Show some evaluation criteria on the clasifier\n",
    "def evaluate_model(x_train, y_train, x_validation, y_validation, classifier):\n",
    "    features = x_train.columns\n",
    "    validation_Prediction = classifier.predict(x_validation)\n",
    "    validation_PredictedProb = classifier.predict_proba(x_validation)[:, 1]\n",
    "    ### ROC metric and curve #####\n",
    "    clasifierName = type(classifier).__name__\n",
    "    metric_RocAuc(validation_PredictedProb, y_validation,clasifierName)\n",
    "    fi_model = pd.DataFrame({'feature': features,\n",
    "                   'importance': classifier.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)\n",
    "    clasifierNameExtended = clasifierName + \"_info_fi\"     \n",
    "    fi_model.to_csv(clasifierNameExtended, index = None)\n",
    "    return fi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> /n <class 'numpy.ndarray'> /n <class 'pandas.core.frame.DataFrame'> /n <class 'numpy.ndarray'> /n\n"
     ]
    }
   ],
   "source": [
    "# classifier = joblib.load(\"rf_RandomSearch.pkl\")\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 400, criterion = 'entropy', random_state = 42, max_depth = 20,\n",
    "        bootstrap =True)\n",
    "\n",
    "print(type(x_train),\"/n\", type(y_train),\"/n\", type(x_validation),\"/n\", type(y_validation),\"/n\", )\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_validation)\n",
    "accuracy = accuracy_score(y_validation, y_pred)\n",
    "# recording[str(i)] = accuracy\n",
    "print(str(i) + \"_Accuracy: %.2f%%\" % (accuracy))\n",
    "evaluate_model(x_train, y_train, x_validation, y_validation, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- S.No\n",
      "- topo_elevation_apr\n",
      "- topo_elevation_aug\n",
      "- topo_elevation_dec\n",
      "- topo_elevation_feb\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Unnamed: 0\n",
      "- topoElevationMean\n",
      "- topoSlope\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 217 features, but RandomForestClassifier is expecting 196 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zg/9gnpzxf5429_p5r9cqlb3_1c0000gn/T/ipykernel_23652/1719641565.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msavingModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RF_400estimators.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_nolabels_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictOnSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_nolabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msavePrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_nolabels_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RF_400estimators.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zg/9gnpzxf5429_p5r9cqlb3_1c0000gn/T/ipykernel_23652/3059813873.py\u001b[0m in \u001b[0;36mpredictOnSet\u001b[0;34m(model, x_test)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredictOnSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    567\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    568\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 217 features, but RandomForestClassifier is expecting 196 features as input."
     ]
    }
   ],
   "source": [
    "savingModels(classifier, \"RF_400estimators.pkl\")\n",
    "\n",
    "test_nolabels_prediction = predictOnSet(classifier, test_nolabels)\n",
    "savePrediction(test_nolabels_prediction, 'RF_400estimators.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
